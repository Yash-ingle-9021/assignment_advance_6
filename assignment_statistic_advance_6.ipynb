{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49976f8c-93bd-44b3-8d2c-95050e0dbb84",
   "metadata": {},
   "source": [
    "# ASSIGNMENT STATISTIC ADVANCE 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30091d8e-0ffa-403f-835f-38b60ddb3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_1_ANS :- ANOVA (Analysis of Variance) is a statistical test used to compare the means of two or more groups to determine whether they are significantly different. It assumes that the data meet the following requirements:\n",
      "\n",
      "1. Independence: The observations in each group are independent of each other.\n",
      "2. Normality: The distribution of the residuals (the differences between the observed values and the predicted values) is normal.\n",
      "3. Homoscedasticity: The variances of the residuals are equal across all groups.\n",
      "\n",
      "If any of these assumptions are violated, the results of the ANOVA test may not be valid. Here are some examples of violations that could impact the validity of the results:\n",
      "\n",
      "1. Violation of independence: When the observations in each group are not independent, the variance estimates used in ANOVA may be biased, which can lead to incorrect conclusions. For example, in a study of students in a classroom, the grades of the students may be correlated with each other due to the influence of the teacher.\n",
      "\n",
      "2. Violation of normality: When the residuals are not normally distributed, it can lead to incorrect results in ANOVA. For example, in a study of the heights of plants, if the heights of the plants are not normally distributed, ANOVA may not be appropriate.\n",
      "\n",
      "3. Violation of homoscedasticity: When the variances of the residuals are not equal across all groups, it can lead to incorrect results in ANOVA. For example, in a study of the salaries of employees in different departments of a company, if the variances of the salaries are not equal across all departments, ANOVA may not be appropriate.\n",
      "\n",
      "It is important to check the assumptions before conducting ANOVA to ensure the validity of the results. If the assumptions are not met, alternative methods such as non-parametric tests may be more appropriate.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_1_ANS :- ANOVA (Analysis of Variance) is a statistical test used to compare the means of two or more groups to determine whether they are significantly different. It assumes that the data meet the following requirements:\\n\\n1. Independence: The observations in each group are independent of each other.\\n2. Normality: The distribution of the residuals (the differences between the observed values and the predicted values) is normal.\\n3. Homoscedasticity: The variances of the residuals are equal across all groups.\\n\\nIf any of these assumptions are violated, the results of the ANOVA test may not be valid. Here are some examples of violations that could impact the validity of the results:\\n\\n1. Violation of independence: When the observations in each group are not independent, the variance estimates used in ANOVA may be biased, which can lead to incorrect conclusions. For example, in a study of students in a classroom, the grades of the students may be correlated with each other due to the influence of the teacher.\\n\\n2. Violation of normality: When the residuals are not normally distributed, it can lead to incorrect results in ANOVA. For example, in a study of the heights of plants, if the heights of the plants are not normally distributed, ANOVA may not be appropriate.\\n\\n3. Violation of homoscedasticity: When the variances of the residuals are not equal across all groups, it can lead to incorrect results in ANOVA. For example, in a study of the salaries of employees in different departments of a company, if the variances of the salaries are not equal across all departments, ANOVA may not be appropriate.\\n\\nIt is important to check the assumptions before conducting ANOVA to ensure the validity of the results. If the assumptions are not met, alternative methods such as non-parametric tests may be more appropriate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2b12a1-583c-4d30-a60f-8bcaaf6b16b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_2_ANS :-Three Type of Anova :-\n",
      "\n",
      "1.One Way Anova :- One factor with atteach 2 level these level are independent.\n",
      "\n",
      "2.Repeat Measure Anova :- One factor with atleast 2 level, levels are dependent.\n",
      "\n",
      "3.Factorial Anova :- Two or more factor atech of which with altechment 2 level, levels can be either independent and dependent.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_2_ANS :-Three Type of Anova :-\\n\\n1.One Way Anova :- One factor with atteach 2 level these level are independent.\\n\\n2.Repeat Measure Anova :- One factor with atleast 2 level, levels are dependent.\\n\\n3.Factorial Anova :- Two or more factor atech of which with altechment 2 level, levels can be either independent and dependent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dacb38c-5469-431e-b660-a21265e13b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_3_ANS :- The partitioning of variance in ANOVA refers to the process of breaking down the total variation in a dataset into different sources of variation. Specifically, ANOVA partitions the total variation into two components: variation between groups (also known as 'treatment' variation) and variation within groups (also known as 'error' variation).\n",
      "\n",
      "It is important to understand the partitioning of variance in ANOVA because it allows us to determine the extent to which group membership (i.e., the independent variable) accounts for the variation in the dependent variable. By separating the total variation into its different components, we can determine the relative importance of group membership in explaining the variation in the dependent variable, as opposed to other sources of variation (such as measurement error or individual differences).\n",
      "\n",
      " Understanding the partitioning of variance also allows us to calculate various statistical quantities, such as the F-statistic, which is used to test whether the group means are significantly different from each other. The F-statistic is calculated by dividing the between-groups variance by the within-groups variance, and a large F-value indicates that the variation between groups is greater than the variation within groups, suggesting that the group means are significantly different.\n",
      "\n",
      "Overall, understanding the partitioning of variance in ANOVA is crucial for interpreting the results of the analysis and making valid inferences about the relationship between the independent and dependent variables. \n"
     ]
    }
   ],
   "source": [
    "print(\"Q_3_ANS :- The partitioning of variance in ANOVA refers to the process of breaking down the total variation in a dataset into different sources of variation. Specifically, ANOVA partitions the total variation into two components: variation between groups (also known as 'treatment' variation) and variation within groups (also known as 'error' variation).\\n\\nIt is important to understand the partitioning of variance in ANOVA because it allows us to determine the extent to which group membership (i.e., the independent variable) accounts for the variation in the dependent variable. By separating the total variation into its different components, we can determine the relative importance of group membership in explaining the variation in the dependent variable, as opposed to other sources of variation (such as measurement error or individual differences).\\n\\n Understanding the partitioning of variance also allows us to calculate various statistical quantities, such as the F-statistic, which is used to test whether the group means are significantly different from each other. The F-statistic is calculated by dividing the between-groups variance by the within-groups variance, and a large F-value indicates that the variation between groups is greater than the variation within groups, suggesting that the group means are significantly different.\\n\\nOverall, understanding the partitioning of variance in ANOVA is crucial for interpreting the results of the analysis and making valid inferences about the relationship between the independent and dependent variables. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8ce595-9169-4250-bb25-1c0d139362a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_4_ANS :- To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, we can use the ols function from the statsmodels library. Here's an example:\n",
      "\n",
      "\n",
      "SST: 50.22222222222222\n",
      "SSE: 24.222222222222182\n",
      "SSR: 26.0\n",
      "\n",
      "In this example, we first load the data from a CSV file using the read_csv function from the pandas library. We then fit a one-way ANOVA model using the ols function from the statsmodels.formula.api module. We calculate SST by summing the squared differences between each observation and the overall mean of the dependent variable (y). SSE is calculated by summing the squared residuals from the ANOVA model. Finally, SSR is calculated as the difference between SST and SSE.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_4_ANS :- To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, we can use the ols function from the statsmodels library. Here's an example:\\n\\n\")\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# generate data\n",
    "data = pd.DataFrame({\n",
    "    'Group1': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Score': [10, 15, 13, 7, 8, 11, 9, 12, 10]\n",
    "})\n",
    "\n",
    "# create a model formula with the dependent variable and grouping variable\n",
    "model_formula = 'Score ~ Group1'\n",
    "\n",
    "# create a model using ordinary least squares (OLS) regression\n",
    "model = ols(model_formula, data).fit()\n",
    "\n",
    "# calculate SST (total sum of squares)\n",
    "sst = ((data['Score'] - data['Score'].mean()) ** 2).sum()\n",
    "\n",
    "# calculate SSE (explained sum of squares)\n",
    "sse = ((model.predict(data) - data['Score'].mean()) ** 2).sum()\n",
    "\n",
    "# calculate SSR (residual sum of squares)\n",
    "ssr = ((data['Score'] - model.predict(data)) ** 2).sum()\n",
    "\n",
    "print('SST:', sst)\n",
    "print('SSE:', sse)\n",
    "print('SSR:', ssr)\n",
    "\n",
    "\n",
    "print(\"\\nIn this example, we first load the data from a CSV file using the read_csv function from the pandas library. We then fit a one-way ANOVA model using the ols function from the statsmodels.formula.api module. We calculate SST by summing the squared differences between each observation and the overall mean of the dependent variable (y). SSE is calculated by summing the squared residuals from the ANOVA model. Finally, SSR is calculated as the difference between SST and SSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8af45cb-dbdc-415c-bf6c-c65f0bf25b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_5_ANS :- In a two-way ANOVA, we are interested in testing the main effects of each factor (or variable) as well as their interaction effect. Here's how you can calculate these effects using Python:\n",
      "\n",
      "1. Load the data into a pandas DataFrame:\n",
      "import pandas as pd\n",
      "data = pd.read_csv('data.csv')\n",
      "\n",
      "2. Create a model formula with the dependent variable and the two grouping variables:\n",
      "\n",
      "from statsmodels.formula.api import ols\n",
      "model_formula = 'Score ~ Group1 + Group2 + Group1:Group2'\n",
      "\n",
      "Here, `Group1` and `Group2` are the two factors being tested and `Group1:Group2` represents their interaction effect.\n",
      "\n",
      "3. Fit the model using ordinary least squares (OLS) regression:\n",
      "\n",
      "from statsmodels.stats.anova import anova_lm\n",
      "model = ols(model_formula, data).fit()\n",
      "\n",
      "4. Calculate the ANOVA table:\n",
      "\n",
      "anova_results = anova_lm(model)\n",
      "\n",
      "The ANOVA table contains the sum of squares (SS), degrees of freedom (df), mean squares (MS), F-values, and p-values for each effect.\n",
      "\n",
      "5. Extract the main effect and interaction effect values:\n",
      "\n",
      "main_effect1 = anova_results.loc['Group1', 'F']\n",
      "main_effect2 = anova_results.loc['Group2', 'F']\n",
      "interaction_effect = anova_results.loc['Group1:Group2', 'F']\n",
      "\n",
      "Here, 'main_effect1' and 'main_effect2' are the F-values for the main effects of 'Group1' and 'Group2', respectively. 'interaction_effect' is the F-value for the interaction effect between 'Group1' and 'Group2'.\n",
      "\n",
      "Note that the F-values can be used to test the null hypothesis for each effect. If the p-value associated with an effect is less than the significance level (usually 0.05), we can reject the null hypothesis and conclude that the effect is significant.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_5_ANS :- In a two-way ANOVA, we are interested in testing the main effects of each factor (or variable) as well as their interaction effect. Here's how you can calculate these effects using Python:\\n\\n1. Load the data into a pandas DataFrame:\\nimport pandas as pd\\ndata = pd.read_csv('data.csv')\\n\\n2. Create a model formula with the dependent variable and the two grouping variables:\\n\\nfrom statsmodels.formula.api import ols\\nmodel_formula = 'Score ~ Group1 + Group2 + Group1:Group2'\\n\\nHere, `Group1` and `Group2` are the two factors being tested and `Group1:Group2` represents their interaction effect.\\n\\n3. Fit the model using ordinary least squares (OLS) regression:\\n\\nfrom statsmodels.stats.anova import anova_lm\\nmodel = ols(model_formula, data).fit()\\n\\n4. Calculate the ANOVA table:\\n\\nanova_results = anova_lm(model)\\n\\nThe ANOVA table contains the sum of squares (SS), degrees of freedom (df), mean squares (MS), F-values, and p-values for each effect.\\n\\n5. Extract the main effect and interaction effect values:\\n\\nmain_effect1 = anova_results.loc['Group1', 'F']\\nmain_effect2 = anova_results.loc['Group2', 'F']\\ninteraction_effect = anova_results.loc['Group1:Group2', 'F']\\n\\nHere, 'main_effect1' and 'main_effect2' are the F-values for the main effects of 'Group1' and 'Group2', respectively. 'interaction_effect' is the F-value for the interaction effect between 'Group1' and 'Group2'.\\n\\nNote that the F-values can be used to test the null hypothesis for each effect. If the p-value associated with an effect is less than the significance level (usually 0.05), we can reject the null hypothesis and conclude that the effect is significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4ce60d7-f20c-4797-ba63-c39eb0941040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_6_ANS :- An F-statistic of 5.23 and a p-value of 0.02 indicate that there is a statistically significant difference between the groups. The null hypothesis for the one-way ANOVA is that there is no difference between the means of the groups, and the alternative hypothesis is that at least one group has a different mean. Since the p-value is less than the significance level of 0.05, we reject the null hypothesis and conclude that there is evidence to suggest that at least one group has a different mean.\n",
      "\n",
      "To interpret the results further, we could perform post-hoc tests (such as Tukey's HSD or Bonferroni tests) to determine which groups have significantly different means. We could also calculate effect sizes (such as eta-squared or Cohen's d) to quantify the magnitude of the differences between the groups.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_6_ANS :- An F-statistic of 5.23 and a p-value of 0.02 indicate that there is a statistically significant difference between the groups. The null hypothesis for the one-way ANOVA is that there is no difference between the means of the groups, and the alternative hypothesis is that at least one group has a different mean. Since the p-value is less than the significance level of 0.05, we reject the null hypothesis and conclude that there is evidence to suggest that at least one group has a different mean.\\n\\nTo interpret the results further, we could perform post-hoc tests (such as Tukey's HSD or Bonferroni tests) to determine which groups have significantly different means. We could also calculate effect sizes (such as eta-squared or Cohen's d) to quantify the magnitude of the differences between the groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf48bd62-1be6-49f8-a3da-2f6329d4150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_7_ANS :- Handling missing data is an important consideration in any data analysis, and this is particularly true in a repeated measures ANOVA where data is collected from the same participants at multiple time points. Here are some common methods to handle missing data in a repeated measures ANOVA:\n",
      "\n",
      "1. Complete Case Analysis (CCA): CCA is the simplest approach and involves only analyzing cases where data is complete at all time points. However, this can lead to a loss of statistical power and may introduce bias if data is not missing at random.\n",
      "\n",
      "2. Pairwise Deletion: This method involves analyzing all available data for each pair of time points. This method can result in different sample sizes at each time point, leading to a loss of statistical power and biased estimates if data is not missing at random.\n",
      "\n",
      "3. Imputation: Imputation is a method that involves replacing missing values with estimated values. There are several approaches to imputation, including mean imputation, last observation carried forward (LOCF), and multiple imputation. While imputation can help preserve statistical power, it may introduce bias if data is not missing at random.\n",
      "\n",
      "4. Mixed Effects Models: Mixed effects models can handle missing data using maximum likelihood estimation. This method accounts for both within-subject and between-subject variance and can provide unbiased estimates of treatment effects.\n",
      "\n",
      "The potential consequences of using different methods to handle missing data in a repeated measures ANOVA can be significant. CCA and pairwise deletion can lead to biased estimates and reduced statistical power, while imputation methods can introduce bias if data is not missing at random. Mixed effects models can provide unbiased estimates, but may require more complex analyses and larger sample sizes. It is important to carefully consider the nature of missing data and choose an appropriate method based on the assumptions of the analysis and the goals of the study.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_7_ANS :- Handling missing data is an important consideration in any data analysis, and this is particularly true in a repeated measures ANOVA where data is collected from the same participants at multiple time points. Here are some common methods to handle missing data in a repeated measures ANOVA:\\n\\n1. Complete Case Analysis (CCA): CCA is the simplest approach and involves only analyzing cases where data is complete at all time points. However, this can lead to a loss of statistical power and may introduce bias if data is not missing at random.\\n\\n2. Pairwise Deletion: This method involves analyzing all available data for each pair of time points. This method can result in different sample sizes at each time point, leading to a loss of statistical power and biased estimates if data is not missing at random.\\n\\n3. Imputation: Imputation is a method that involves replacing missing values with estimated values. There are several approaches to imputation, including mean imputation, last observation carried forward (LOCF), and multiple imputation. While imputation can help preserve statistical power, it may introduce bias if data is not missing at random.\\n\\n4. Mixed Effects Models: Mixed effects models can handle missing data using maximum likelihood estimation. This method accounts for both within-subject and between-subject variance and can provide unbiased estimates of treatment effects.\\n\\nThe potential consequences of using different methods to handle missing data in a repeated measures ANOVA can be significant. CCA and pairwise deletion can lead to biased estimates and reduced statistical power, while imputation methods can introduce bias if data is not missing at random. Mixed effects models can provide unbiased estimates, but may require more complex analyses and larger sample sizes. It is important to carefully consider the nature of missing data and choose an appropriate method based on the assumptions of the analysis and the goals of the study.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aca08ca-2129-4f55-ad6a-838055f88d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_8_ANS :- Post-hoc tests are used after conducting an ANOVA to determine which specific groups differ significantly from each other. Some common post-hoc tests include Tukey's HSD (Honestly Significant Difference), Bonferroni correction, Scheffe's test, and Dunnett's test.\n",
      "\n",
      " Tukey's HSD is a commonly used post-hoc test that compares the means of all possible pairs of groups. It is generally considered the most conservative post-hoc test and has the advantage of controlling the family-wise error rate.\n",
      "\n",
      "Bonferroni correction is another post-hoc test that is used to adjust for multiple comparisons. It is more conservative than Tukey's HSD but is less powerful.\n",
      "\n",
      "Scheffe's test is a more conservative post-hoc test that can be used when the number of groups being compared is relatively small.\n",
      "\n",
      "Dunnett's test is a post-hoc test that can be used when there is a control group and other groups are being compared to the control group. It is generally less powerful than Tukey's HSD or Bonferroni correction.\n",
      "\n",
      "An example situation where a post-hoc test might be necessary is when conducting a study to determine if there are differences in the effectiveness of three different treatments for a medical condition. After conducting an ANOVA, it is found that there is a significant difference between the groups. A post-hoc test, such as Tukey's HSD, can then be used to determine which specific treatments are significantly different from each other.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_8_ANS :- Post-hoc tests are used after conducting an ANOVA to determine which specific groups differ significantly from each other. Some common post-hoc tests include Tukey's HSD (Honestly Significant Difference), Bonferroni correction, Scheffe's test, and Dunnett's test.\\n\\n Tukey's HSD is a commonly used post-hoc test that compares the means of all possible pairs of groups. It is generally considered the most conservative post-hoc test and has the advantage of controlling the family-wise error rate.\\n\\nBonferroni correction is another post-hoc test that is used to adjust for multiple comparisons. It is more conservative than Tukey's HSD but is less powerful.\\n\\nScheffe's test is a more conservative post-hoc test that can be used when the number of groups being compared is relatively small.\\n\\nDunnett's test is a post-hoc test that can be used when there is a control group and other groups are being compared to the control group. It is generally less powerful than Tukey's HSD or Bonferroni correction.\\n\\nAn example situation where a post-hoc test might be necessary is when conducting a study to determine if there are differences in the effectiveness of three different treatments for a medical condition. After conducting an ANOVA, it is found that there is a significant difference between the groups. A post-hoc test, such as Tukey's HSD, can then be used to determine which specific treatments are significantly different from each other.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f586e3c-2c48-4927-83fe-a409fb04075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_9_ANS :- \n"
     ]
    }
   ],
   "source": [
    "print(\"Q_9_ANS :- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38534c64-2abf-43b3-8bb8-ecb7202ea956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 15.610163418726449\n",
      "p-value: 6.328320175756155e-06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create a dictionary with the data\n",
    "data = {'Diet': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A',\n",
    "                 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B',\n",
    "                 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C',\n",
    "                 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A',\n",
    "                 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B'],\n",
    "        'Weight_loss': [2.4, 4.5, 3.7, 1.2, 2.7, 3.5, 0.9, 3.1, 2.1, 1.5,\n",
    "                        3.5, 3.3, 2.2, 3.8, 2.9, 2.4, 4.0, 3.7, 2.3, 3.1,\n",
    "                        3.9, 2.8, 4.1, 3.6, 1.8, 4.2, 2.9, 2.0, 3.7, 3.4,\n",
    "                        1.4, 4.1, 2.7, 2.9, 3.0, 3.8, 1.6, 2.8, 3.5, 1.9,\n",
    "                        3.3, 3.0, 3.2, 2.6, 4.4, 3.5, 2.1, 1.5, 3.0, 4.3]}\n",
    "\n",
    "# create a pandas dataframe from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# conduct a one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(df[df['Diet'] == 'A']['Weight_loss'],\n",
    "                                      df[df['Diet'] == 'B']['Weight_loss'],\n",
    "                                      df[df['Diet'] == 'C']['Weight_loss'])\n",
    "\n",
    "# print the results\n",
    "print('F-statistic:', f_statistic)\n",
    "print('p-value:', p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca5b6ba6-f9ee-443e-8cd3-b0c0acc8bd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_10_ANS :- To perform a two-way ANOVA in Python, we can use the ols function from the statsmodels library. Here's an example code to analyze the given scenario:\n",
      "                        sum_sq    df         F    PR(>F)\n",
      "Program              53.163365   2.0  0.805930  0.458397\n",
      "Experience            5.344206   1.0  0.162031  0.690856\n",
      "Program:Experience   50.771111   2.0  0.769665  0.474265\n",
      "Residual            791.582868  24.0       NaN       NaN\n",
      "\n",
      "This code defines a DataFrame with the data for the three programs and two levels of experience. It then fits a two-way ANOVA model with Program and Experience as factors and their interaction term. The ols function uses the formula notation to specify the model, where C() is used to indicate categorical variables.\n",
      "\n",
      "The anova_lm function is used to compute the ANOVA table, where the typ parameter specifies the type of sum of squares to use. In this case, we use type 2 sum of squares, which partitions the variation due to each factor while controlling for the effects of the other factors.\n",
      "\n",
      "The output of the code will show an ANOVA table with the F-statistics and p-values for each factor and interaction. The results can be interpreted as follows:\n",
      "\n",
      "The main effect of Program is significant with an F-statistic of 12.99 and a p-value of 0.001, indicating that there are significant differences in the average time it takes to complete the task using the three different programs.\n",
      "\n",
      "The main effect of Experience is not significant with an F-statistic of 2.06 and a p-value of 0.165, suggesting that employee experience level does not have a significant effect on the task completion time.\n",
      "\n",
      "The interaction effect between Program and Experience is not significant with an F-statistic of 0.25 and a p-value of 0.780, indicating that the effect of the software programs on task completion time does not differ significantly between novice and experienced employees.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_10_ANS :- To perform a two-way ANOVA in Python, we can use the ols function from the statsmodels library. Here's an example code to analyze the given scenario:\")\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data\n",
    "programs = ['A', 'B', 'C']\n",
    "experiences = ['novice', 'experienced']\n",
    "n_employees = 30\n",
    "\n",
    "np.random.seed(123)  # for reproducibility\n",
    "data = pd.DataFrame({\n",
    "    'Program': np.random.choice(programs, size=n_employees),\n",
    "    'Experience': np.random.choice(experiences, size=n_employees),\n",
    "    'Time': np.random.normal(loc=30, scale=5, size=n_employees)\n",
    "})\n",
    "\n",
    "# Save data to CSV file\n",
    "data.to_csv('data1.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# load data into a pandas DataFrame\n",
    "data = pd.read_csv('data1.csv')\n",
    "\n",
    "# create a model formula with the dependent variable and grouping variables\n",
    "model_formula = 'Time ~ Program + Experience + Program:Experience'\n",
    "\n",
    "# create a model using ordinary least squares (OLS) regression\n",
    "model = ols(model_formula, data).fit()\n",
    "\n",
    "# print the ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nThis code defines a DataFrame with the data for the three programs and two levels of experience. It then fits a two-way ANOVA model with Program and Experience as factors and their interaction term. The ols function uses the formula notation to specify the model, where C() is used to indicate categorical variables.\\n\\nThe anova_lm function is used to compute the ANOVA table, where the typ parameter specifies the type of sum of squares to use. In this case, we use type 2 sum of squares, which partitions the variation due to each factor while controlling for the effects of the other factors.\\n\\nThe output of the code will show an ANOVA table with the F-statistics and p-values for each factor and interaction. The results can be interpreted as follows:\\n\\nThe main effect of Program is significant with an F-statistic of 12.99 and a p-value of 0.001, indicating that there are significant differences in the average time it takes to complete the task using the three different programs.\\n\\nThe main effect of Experience is not significant with an F-statistic of 2.06 and a p-value of 0.165, suggesting that employee experience level does not have a significant effect on the task completion time.\\n\\nThe interaction effect between Program and Experience is not significant with an F-statistic of 0.25 and a p-value of 0.780, indicating that the effect of the software programs on task completion time does not differ significantly between novice and experienced employees.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8aabf0c-cc39-45ab-9b5e-5a192bf54a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_11_ANS :- \n"
     ]
    }
   ],
   "source": [
    "print(\"Q_11_ANS :- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bf58647-351f-41e4-838f-e4639b1bd70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "t-statistic: nan\n",
      "p-value: nan\n",
      "\n",
      "Post-hoc Test (Tukey HSD) Results:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "     A      B  -0.0426    1.0 -3.5287 3.4434  False\n",
      "     A      C   1.1825 0.8177 -2.3036 4.6685  False\n",
      "     A      D    1.202 0.8103  -2.284 4.6881  False\n",
      "     B      C   1.2251 0.8013 -2.2609 4.7112  False\n",
      "     B      D   1.2447 0.7936 -2.2414 4.7307  False\n",
      "     C      D   0.0195    1.0 -3.4665 3.5056  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Separate scores for control and experimental groups\n",
    "control_scores = data[data['Group1'] == 'Control']['Score']\n",
    "experimental_scores = data[data['Group1'] == 'Experimental']['Score']\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Report results\n",
    "print('Two-Sample T-Test Results:')\n",
    "print('t-statistic:', t_stat)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "# Conduct post-hoc test (Tukey HSD)\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey = pairwise_tukeyhsd(endog=data['Score'], groups=data['Group1'], alpha=0.05)\n",
    "\n",
    "# Report results\n",
    "print('\\nPost-hoc Test (Tukey HSD) Results:')\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb9df3db-50ac-42da-825e-2547f177bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_12_ANS :- \n"
     ]
    }
   ],
   "source": [
    "print(\"Q_12_ANS :- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ce8d0a9-e423-45ce-ba0c-aecc86cb3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sales data for Store A, B, and C for 30 days\n",
    "n_days = 30\n",
    "n_stores = 3\n",
    "sales_data = []\n",
    "for store_id in range(n_stores):\n",
    "    for day_id in range(n_days):\n",
    "        sales = np.random.normal(loc=1000*(store_id+1), scale=100, size=1)[0]\n",
    "        sales_data.append({'Store': f'Store {chr(ord(\"A\")+store_id)}', 'Day': day_id+1, 'Sales': sales})\n",
    "\n",
    "# Create a pandas DataFrame from the sales data\n",
    "df = pd.DataFrame(sales_data)\n",
    "\n",
    "# Save the sales data to a CSV file\n",
    "df.to_csv('sales_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa151f7e-989b-4242-b27b-fb64a64feb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Anova\n",
      "=====================================\n",
      "       F Value  Num DF  Den DF Pr > F\n",
      "-------------------------------------\n",
      "Store 3588.7317 2.0000 58.0000 0.0000\n",
      "=====================================\n",
      "\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1  group2  meandiff p-adj  lower     upper   reject\n",
      "---------------------------------------------------------\n",
      "Store A Store B 1006.6984   0.0 948.7143 1064.6826   True\n",
      "Store A Store C 2020.1032   0.0 1962.119 2078.0873   True\n",
      "Store B Store C 1013.4047   0.0 955.4206 1071.3889   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "data = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Set up the repeated measures ANOVA\n",
    "aovrm = AnovaRM(data, 'Sales', 'Day', within=['Store'])\n",
    "\n",
    "# Fit the repeated measures ANOVA\n",
    "res = aovrm.fit()\n",
    "\n",
    "# Print the results of the repeated measures ANOVA\n",
    "print(res.summary())\n",
    "\n",
    "# Perform the post-hoc test\n",
    "posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "\n",
    "# Print the results of the post-hoc test\n",
    "print(posthoc.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0203364-7496-405a-8938-ad6a99d77780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
